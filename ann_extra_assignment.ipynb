{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann extra assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0G338PLHMm2",
        "colab_type": "code",
        "outputId": "d984fb04-ed5f-46a3-d91d-5527f2d377fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import time\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUalLwfTI8xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWFoGGQMI-27",
        "colab_type": "code",
        "outputId": "a4300009-023b-44bf-d842-f5213ce3b8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh7Kf_S6I_FW",
        "colab_type": "code",
        "outputId": "f733aed4-8a9b-4a1a-9db1-e594d4a79328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlgNhaYjI_Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.C1 = nn.Conv2d(1, 32, kernel_size=(3, 3))\n",
        "        self.C2 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
        "        self.S3 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.F5 = nn.Linear(9216,128)\n",
        "        self.dropout1 = nn.Dropout(p=0.25)\n",
        "        self.dropout2 = nn.Dropout(p=0.5)\n",
        "        # output layer\n",
        "        self.OL = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "  \n",
        "        x =  self.S3(F.relu(self.C2(self.C1(x))))\n",
        "        x = x.view(-1, 9216)\n",
        "        x =  self.dropout1(x)\n",
        "        x =  F.relu(self.F5(x))\n",
        "        x =  self.dropout2(x)\n",
        "        x =  x.view(x.size(0), -1) \n",
        "        x = F.log_softmax(self.OL(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model=LeNet5()        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5f2eOOhhhK7",
        "colab_type": "code",
        "outputId": "d002bd92-6384-42dd-c1ef-e02ddcadf90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "for device in [ 'cpu','cuda']:\n",
        "  model.to(device)\n",
        "  ntrain = images.shape[0];  # number of training examples\n",
        "  nepoch = 7;                   \n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "  criterion = nn.NLLLoss()\n",
        "  for iepoch in range(nepoch):\n",
        "\n",
        "      model.train()  \n",
        "      train_loss = 0\n",
        "      optimizer.zero_grad()\n",
        "      for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)   \n",
        "        optimizer.zero_grad()\n",
        "        start = time.time()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "         \n",
        "     \n",
        "      print(f\"Training loss: {train_loss/len(trainloader)}\")     \n",
        "  print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.25887538891619266\n",
            "Training loss: 0.09929009890213593\n",
            "Training loss: 0.07639223789976937\n",
            "Training loss: 0.06377856046987027\n",
            "Training loss: 0.054822534252368195\n",
            "Training loss: 0.0473607827608696\n",
            "Training loss: 0.04287828010720894\n",
            "Device = cpu; Time per batch: 0.015 seconds\n",
            "Training loss: 0.03876938024309398\n",
            "Training loss: 0.03326686443105689\n",
            "Training loss: 0.032122594469201085\n",
            "Training loss: 0.030080452082809735\n",
            "Training loss: 0.02700204211575136\n",
            "Training loss: 0.02733600677362383\n",
            "Training loss: 0.025287737768056043\n",
            "Device = cuda; Time per batch: 0.001 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axr4Rcfghhh0",
        "colab_type": "code",
        "outputId": "490094f7-fc4e-46e5-fcbe-9ac34f86d960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "if train_on_gpu:\n",
        "  model.cuda()\n",
        "test_loss = 0.0\n",
        "classes = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "batch_size = 32\n",
        "model.eval()\n",
        "\n",
        "for images, labels in testloader:\n",
        "    if train_on_gpu:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "    logits = model(images)\n",
        "    loss = criterion(logits, labels)\n",
        "    test_loss += loss.item()\n",
        "    _, pred = torch.max(logits, 1)  \n",
        "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "    correct =  np.squeeze(correct_tensor.cpu().numpy())\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        label = labels.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "test_loss = test_loss/len(testloader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %.6f%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %.6f%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))      \n",
        "         \n",
        "     "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.000073\n",
            "\n",
            "Test Accuracy of     1: 100.000000% (2946/2946)\n",
            "Test Accuracy of     2: 99.909802% (3323/3326)\n",
            "Test Accuracy of     3: 99.934512% (3052/3054)\n",
            "Test Accuracy of     4: 99.837820% (3078/3083)\n",
            "Test Accuracy of     5: 99.931834% (2932/2934)\n",
            "Test Accuracy of     6: 99.961905% (2624/2625)\n",
            "Test Accuracy of     7: 99.830967% (2953/2958)\n",
            "Test Accuracy of     8: 99.591580% (3170/3183)\n",
            "Test Accuracy of     9: 100.000000% (2978/2978)\n",
            "Test Accuracy of     0: 99.795152% (2923/2929)\n",
            "\n",
            "Test Accuracy (Overall): 99.876732% (29979/30016)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}